Vertex AI
Documentation
Generative AI
Was this helpful?
Send feedback
Overview of language models
On this page
Vertex AI PaLM API
Vertex AI Codey APIs
Prompt design
Model tuning
What's next
You can access, tune, and deploy Google's generative AI language models by using the Vertex AI PaLM API and Vertex AI Codey APIs. Use the language models to perform a variety of workflows from Vertex AI, like use the APIs to interact with the models and deploy the models to a Jupyter notebook. You can also customize language models for your specific use case by performing model tuning. This page gives you an overview of the available language models, the APIs you use to interact with the models, and ways to customize their behaviors.
Note: If you're new to generative AI or are not sure where to start, you can start prototyping with PaLM 2 in MakerSuite. Note that MakerSuite is not for enterprise use cases that require advanced security control and compliance.
Vertex AI PaLM API
The Vertex AI PaLM API gives you access to the PaLM 2 family of models, which support the generation of natural language text, text embeddings, and code (we recommend using the Vertex AI Codey APIs for code generation). PaLM 2 is the second generation of the Pathways Language Model developed by Google Labs. By using the Vertex AI PaLM API, you can leverage the MLOps tools, enterprise-level security, safety, privacy, and scalability offered by Vertex AI.
The Vertex AI PaLM API exposes PaLM 2 models by using global publisher endpoints that are unique to each Google Cloud project. The following is an example of a publisher model endpoint:
https://us-central1-aiplatform.googleapis.com/v1/projects/your_project_id/locations/us-central1/publishers/google/models/text-bison:predict
The Vertex AI PaLM API has publisher endpoints for the following PaLM 2 models:
text-bison: Optimized for performing natural language tasks, such as classification, summarization, extraction, content creation, and ideation.
chat-bison: Optimized for multi-turn chat, where the model keeps track of previous messages in the chat and uses it as context for generating new responses.
textembedding-gecko: Generates text embeddings for a given text. You can use embeddings for tasks like semantic search, recommendation, classification, and outlier detection.
To learn more about these models, see Available models.
Vertex AI Codey APIs
The Vertex AI Codey APIs are optimized to support code generation, code chat, and code completion for several programming languages. The Vertex AI Codey APIs are based on the PaLM 2 family of models. For more information, see Code models overview.
Prompt design
To interact with foundation models like PaLM 2, you send natural language instructions, also called prompts, that tell the model what you want it to generate. However, LLMs can sometimes behave in unpredictable ways. Prompt design is an iterative process of trial and error that takes time and practice to become proficient in. To learn about general prompt design strategies, see Introduction to prompt design. For task-specific prompt design guidance for text, see Design text prompts.
Model tuning
If you need to customize PaLM 2 models for a specific use case, you can tune the models by using a dataset of input and output examples. Tuned models are automatically deployed to a new endpoint in your project to serve requests. To learn more about model tuning, see Tune foundation models.
What's next
Learn how to design text prompts.
Learn how to design chat prompts.
Learn more about code models.
Learn about streaming responses from a model.
Was this helpful?
Send feedback