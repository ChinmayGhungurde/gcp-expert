Vertex AI
Documentation
Generative AI
Send feedback
Create prompts to chat about code
bookmark_border
On this page
Use cases
Supported model
How to submit a code chat prompt
Submit a prompt (console)
Submit a prompt with curl (REST)
Example code chat prompt
Stream response from code chat model
What's next
The Vertex AI Codey APIs include the code chat API which supports multi-turn conversations that are specialized for code. Use the generative AI foundation model named codechat-bison to interact with the code chat API. This topic helps you learn how to create prompts to work with the codechat-bison model to have a chatbot conversation about code.
Use cases
Some common use cases for code chat are:
Debugging: Get help with debugging code that doesn't compile or that contains a bug.
Documentation: Get help with understanding code so you can document it accurately.
Learning: Get help with learning about code you're not very familiar with.
Supported model
The following model supports code chat tasks:
codechat-bison
How to submit a code chat prompt
You can submit a code chat prompt in the Generative AI Studio, as a REST command, or using Python.
When you submit a prompt, you need to specify values for the temperature and maximum output tokens. For more information, see Code chat model parameters.
Submit a prompt (console)
To run and test a code chat prompt, use the codechat-bison model in Generative AI Studio. For more information about Generative AI Studio, see Introduction to Generative AI Studio.
Do the following to use Generative AI Studio to submit a code chat prompt:
Go to the Generative AI Studio page from the Vertex AI section in the Google Cloud console. Generative AI Studio
On the Language card, click Open.
On Start a conversation, click Code chat.
In Model, select the model with the name that begins with codechat-bison. A three digit number after codechat-bison indicates the version number of the model. For example, codechat-bison@001 is the name of version one of the code chat model.
Adjust Temperature or Token limit to experiment with how they affect the response. For more information, see Code chat model parameters.
In Enter a prompt to begin a conversation, enter a prompt to start a conversation about code.
Click Continue the conversation to submit the prompt to the chat.
After you receive a response, repeat the previous two steps to continue the conversation.
Submit a prompt with curl (REST)
Do the following to use curl submit a code chat prompt:
Log in to the Google Cloud CLI with your user account by doing one of the following:
Run gcloud init or gcloud auth login
Use Cloud Shell, which logs you into the gcloud CLI. You can check the currently active account by running gcloud auth list.
Create a JSON file named request.json.
Enter the following code in request.json.
{
  "instances": {
    "messages": [
        {
          "author": "user",
          "content": "
CONTENT",
        },
        {
          "author": "system",
          "content": "I am doing good. What Can I help you with in the coding world?",
        },
        {
          "author": "user",
          "content": "
CONTENT",
        }
      ]
  },
  "parameters": {
    "temperature": 
TEMPERATURE,
    "maxOutputTokens": 
MAX_OUTPUT_TOKENS,
    "candidateCount": 
CANDIDATE_COUNT
  }
}
In response.json, replace CONTENT and specify your parameters for temperature, and maximum output tokens. For more information, see Code completion model parameters.
In your shell, run the following command. Replace PROJECT_ID with your project ID.
curl -X POST \
    -H "Authorization: Bearer $(gcloud auth print-access-token)" \
    -H "Content-Type: application/json; charset=utf-8" \
    -d @request.json \
    "https://us-central1-aiplatform.googleapis.com/v1/projects/
PROJECT_ID/locations/us-central1/publishers/google/models/codechat-bison:predict"
Example code chat prompt
You can use the code chat model to generate code. In the following example chat, the user requests a function that calculates the minimum of two numbers.
This is the user's first prompt:
Prompt:
      Hi, how are you?
        
Response:
      I am doing well, thank you for asking! I am excited to be able to help people
      with their tasks and answer their questions. How are you doing today?
        
This is the user's second prompt that results in code generation for a function:
Prompt:
Please help write a function to calculate the min of two numbers
  
Response:
Sure, here is the code for a function to calculate the minimum of two numbers in Python:

def min(x, y):
  """
  This function calculates the minimum of two numbers.

  Args:
    x: The first number.
    y: The second number.

  Returns:
    The smaller of the two numbers.
  """

  if x < y:
    return x
  else:
    return y
Here is an example of how to use the min() function:

print(min(10, 5))
This will print the number 5, which is the smaller of the two numbers.
  
Stream response from code chat model
To view sample code requests and responses using the REST API, see Examples using the streaming REST API.
To view sample code requests and responses using the Vertex AI SDK for Python, see Examples using Vertex AI SDK for Python for streaming.
What's next
Learn how to create code chat prompts.
Learn how to create code generation prompts.
Learn about responsible AI best practices and Vertex AI's safety filters.
Send feedback