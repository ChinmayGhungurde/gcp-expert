Vertex AI
Documentation
Generative AI
Was this helpful?
Send feedback
Get text embeddings
bookmark_border
On this page
Supported models
Prerequisites
Get text embeddings for a snippet of text
API changes to models released in or after August 2023
Language coverage for textembedding-gecko-multilingual@latest
Use Vector Search
What's next
With the Vertex AI text-embeddings API, you can easily create a text embedding with Generative AI. A text embedding is a vector representation of text, and they are used in many ways to find similar items. You interact with them every time you complete a Google search, see recommendations when online shopping, or when your favorite music streaming service suggests a rock band you might like based on your listening history. Some common use cases for text embeddings include:
Semantic search: Search text ranked by semantic similarity.
Classification: Return the class of items whose text attributes are similar to the given text.
Clustering: Cluster items whose text attributes are similar to the given text.
Outlier Detection: Return items where text attributes are least related to the given text.
Conversational interface: Clusters groups of sentences which can lead to similar responses, like in a conversation-level embedding space.
When you create text embeddings, you get vector representations of natural text as arrays of floating point numbers. What this means, is that all of your input text is assigned a numerical representation. By comparing the numerical distance between the vector representations of two pieces of text, an application can determine the similarity between the text or the objects represented by the text.
For example, let's say you wanted to develop a book recommendation chatbot. The first thing you would do is use a deep neural network (DNN) to convert each book into an embedding vector, where one embedding vector represents one book. We could feed, as input to the DNN, just the book title or just the text content. Or we could use both of these together, along with any other metadata describing the book, such as the genre.
The embeddings in this example could be comprised of thousands of book titles with summaries and their genre, and it might have representations for books like Wuthering Heights by Emily BrontÃ« and Persuasion by Jane Austen that are similar to each other (small distance between numerical representation). Whereas the numerical representation for the book The Great Gatsby by F. Scott Fitzgerald would be further, as the time period, genre, and summary is less similar.
The inputs are the main influence to the orientation of the embedding space. For example, if we only had book title inputs, then two books with similar titles, but very different summaries, could be close together. However, if we include the title and summary, then these same books are less similar (further away) in the embedding space.
Working with Generative AI, this book-suggestion chatbot could summarize, suggest, and show you books which you might like (or dislike), based on your query.
To learn more about embeddings, see Meet AI's multitool: Vector embeddings. To take a foundational ML crash course on embeddings, see Embeddings.
After converting each book to an embedding representation, it's time to index these embeddings in a vector database, like Vector Search. This enables low-latency retrieval, and is critical as the size of our corpus of books (vectors) increases.
To learn more about Vector Search, see Vector Search ANN service overview.
Supported models
You can get text embeddings by using the following models:
textembedding-gecko@001 (stable)
textembedding-gecko@latest(public preview: an embeddings model with enhanced AI quality)
textembedding-gecko-multilingual@latest (public preview: an embeddings model designed to use a wide range of non-English languages.)
Important: It is strongly recommended to specify a stable model version (for example, @001) for applications that require backward compatible embeddings. If backward compatibility is not a concern and you would like to use the latest model version, you should specify @latest explicitly. If no version is specified, textembedding-gecko will default to textembedding-gecko@001, and textembedding-gecko-multilingual will default to textembedding-gecko-multilingual@latest.
Prerequisites
There are specific prerequisites for successfully creating an embedding. To get started, see quickstart: Try text embeddings.
Use this colab to call the newly released text embedding models (textembedding-gecko and textembedding-gecko-multilingual).
Jupyter notebook: You can run this tutorial as a Jupyter notebook.
Run in Colab
Get text embeddings for a snippet of text
You can get text embeddings for a snippet of text by using the Vertex AI API or the Vertex AI SDK for Python. These samples apply to the stable model version, textembedding-gecko@001.
Note: There is a limit of up to 5 input texts per request.
REST
Vertex AI SDK for Python
Node.js
Java
To get text embeddings, send a POST request by specifying the model ID of the publisher model.
Before using any of the request data, make the following replacements:
PROJECT_ID: Your project ID.
TEXT: The text that you want to generate embeddings for.
HTTP method and URL:
POST https://us-central1-aiplatform.googleapis.com/v1/projects/
PROJECT_ID/locations/us-central1/publishers/google/models/textembedding-gecko:predict
Request JSON body:
{
  "instances": [
    { "content": "
TEXT"}
  ],
}
To send your request, choose one of these options:
curl
PowerShell
Note: The following command assumes that you have logged in to the gcloud CLI with your user account by running gcloud init or gcloud auth login, or by using Cloud Shell, which automatically logs you into the gcloud CLI. You can check the currently active account by running gcloud auth list.
Save the request body in a file named request.json, and execute the following command:
curl -X POST \
    -H "Authorization: Bearer $(gcloud auth print-access-token)" \
    -H "Content-Type: application/json; charset=utf-8" \
    -d @request.json \
    "https://us-central1-aiplatform.googleapis.com/v1/projects/
PROJECT_ID/locations/us-central1/publishers/google/models/textembedding-gecko:predict"








You should receive a JSON response similar to the following. Note that values has been truncated to save space.
Response




































































































































Example curl command
MODEL_ID="textembedding-gecko"
PROJECT_ID=
PROJECT_ID

curl \
-X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json" \
https://us-central1-aiplatform.googleapis.com/v1/projects/
PROJECT_ID/locations/us-central1/publishers/google/models/${MODEL_ID}:predict -d \
$'{
  "instances": [
    { "content": "What is life?"}
  ],
}'
API changes to models released in or after August 2023
In August 2023, two new embeddings models were released in public preview:
textembedding-gecko@latest: An updated version with enhanced AI quality
textembedding-gecko-multilingual@latest: A new embeddings model optimized for a wide range of non-English languages.
For optimal prediction results when using these public preview models, specify the new task type parameter and the optional title (only valid with task_type=RETRIEVAL_DOCUMENT). These new parameters apply to these public preview models and all stable models going forward.
{
  "instances": [
    { 
      "task_type": "RETRIEVAL_DOCUMENT",
      "title": "document title",
      "content": "I would like embeddings for this text!"
    },
  ]
}
The task_type parameter is defined as the intended downstream application to help the model produce better quality embeddings. It is a string that can take on one of the following values:
task_type Description
RETRIEVAL_QUERY Specifies the given text is a query in a search/retrieval setting.
RETRIEVAL_DOCUMENT Specifies the given text is a document in a search/retrieval setting.
SEMANTIC_SIMILARITY Specifies the given text will be used for Semantic Textual Similarity (STS).
CLASSIFICATION Specifies that the embeddings will be used for classification.
CLUSTERING Specifies that the embeddings will be used for clustering.
Language coverage for textembedding-gecko-multilingual@latest
The textembedding-gecko-multilingual@latest model has been evaluated on the following languages: Arabic (ar), Bengali (bn), English (en), Spanish (es), German (de), Persian (fa), Finnish (fi), French (fr), Hindi (hi), Indonesian (id), Japanese (ja), Korean (ko), Russian (ru), Swahili (sw), Telugu (te), Thai (th), Yoruba (yo), Chinese (zh).
Below is the full list of supported languages: Afrikaans, Albanian, Amharic, Arabic, Armenian, Azerbaijani, Basque, Belarusian, Bengali, Bulgarian, Burmese, Catalan, Cebuano, Chichewa, Chinese, Corsican, Czech, Danish, Dutch, English, Esperanto, Estonian, Filipino, Finnish, French, Galician, Georgian, German, Greek, Gujarati, Haitian Creole, Hausa, Hawaiian, Hebrew, Hindi, Hmong, Hungarian, Icelandic, Igbo, Indonesian, Irish, Italian, Japanese, Javanese, Kannada, Kazakh, Khmer, Korean, Kurdish, Kyrgyz, Lao, Latin, Latvian, Lithuanian, Luxembourgish, Macedonian, Malagasy, Malay, Malayalam, Maltese, Maori, Marathi, Mongolian, Nepali, Norwegian, Pashto, Persian, Polish, Portuguese, Punjabi, Romanian, Russian, Samoan, Scottish Gaelic, Serbian, Shona, Sindhi, Sinhala, Slovak, Slovenian, Somali, Sotho, Spanish, Sundanese, Swahili, Swedish, Tajik, Tamil, Telugu, Thai, Turkish, Ukrainian, Urdu, Uzbek, Vietnamese, Welsh, West Frisian, Xhosa, Yiddish, Yoruba, and Zulu.
Use Vector Search
To make use of your text-embedding for large search engines or recommendations systems in production, you can take advantage of Vector Search.
Feature Vertex AI text embedding API Vector Search
Creates text embeddings Yes No
Vector quality High Dependent on where the embedding was created
Suited for Creating high-quality text embeddings (vector representations) which can be used for text classification and question answering Performing large approximate nearest neighbor (ANN) searches, which can power search engines and recommendation systems.
What's next
Learn how to tune a foundation model.
Learn about responsible AI best practices and Vertex AI's safety filters.
Was this helpful?
Send feedback