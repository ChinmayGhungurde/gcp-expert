Vertex AI
Documentation
Generative AI
Was this helpful?
Send feedback
Try text embeddings
On this page
Before you begin
Try text embedding requests
What's next
Use Vertex AI to send text embedding requests to Google's PaLM 2 Large Language Model (LLM) and to receive a response. Test and customize prompts to meet the needs of your application.
Before you begin
Before you can try the chat prompts, you must do the following:
Set up a project and a development environment. The project ID is needed to run the sample code.
Familiarize yourself with the text embedding parameters that you must replace before running the sample code.
Review the text embedding use cases to help you identify which type of sample to create.
Try text embedding requests
The Vertex AI PaLM Embedding API performs online (real-time) predictions, which use text embedding requests as input to the model. The API accepts 3,072 input tokens and outputs 768-dimensional vector embeddings.
You can run the sample code in the Cloud Shell terminal in the Google Cloud console.
Go to Cloud Shell
Edit the placeholders in the sample code, and copy to the console.
   MODEL_ID="textembedding-gecko"
   PROJECT_ID=
PROJECT_ID

   curl \
    -X POST \
    -H "Authorization: Bearer $(gcloud auth print-access-token)" \
    -H "Content-Type: application/json" \
    https://us-central1-aiplatform.googleapis.com/v1/projects/
PROJECT_ID/locations/us-central1/publishers/google/models/${MODEL_ID?}:predict -d \
    $'{
      "instances": [
        { "content": "What is life?"}
      ],
    }'
What's next
Learn about designing text prompts. and text chat prompts.
Learn how to test prompts in Generative AI Studio.
Learn about text embeddings.
Try to tune a language foundation model.
Learn about responsible AI best practices and Vertex AI's safety filters.
Was this helpful?
Send feedback